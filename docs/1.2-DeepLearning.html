<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.269">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Deep Reinforcement Learning - 2&nbsp; Deep learning</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./2-Valuebased.html" rel="next">
<link href="./1.1-BasicRL.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Deep learning</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Deep Reinforcement Learning</a> 
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">Overview</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./1.1-BasicRL.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Basics</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./1.2-DeepLearning.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Deep learning</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./2-Valuebased.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Value-based methods</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./3.1-PolicyGradient.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Policy Gradient methods</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./3.2-ActorCritic.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Advantage Actor-Critic methods</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./3.3-ImportanceSampling.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Off-policy Actor-Critic</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./3.4-DPG.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Deterministic Policy Gradient (DPG)</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./3.5-NaturalGradient.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Natural Gradients</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./3.6-EntropyRL.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Maximum Entropy RL</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./3.7-DistributionalRL.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Distributional learning</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./3.8-OtherPolicyGradient.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Miscellaneous model-free algorithm</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./4-RAM.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Recurrent Attention Models</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./5-ModelBased.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Model-based RL</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./6-Hierarchical.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Hierarchical Reinforcement Learning</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./7-Inverse.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Inverse Reinforcement Learning</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./8-Robotics.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Deep RL for robotics</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./9-Practice.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Deep RL in practice</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">References</a>
  </div>
</li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#deep-neural-networks" id="toc-deep-neural-networks" class="nav-link active" data-scroll-target="#deep-neural-networks"><span class="toc-section-number">2.0.1</span>  Deep neural networks</a></li>
  <li><a href="#convolutional-networks" id="toc-convolutional-networks" class="nav-link" data-scroll-target="#convolutional-networks"><span class="toc-section-number">2.0.2</span>  Convolutional networks</a></li>
  <li><a href="#recurrent-neural-networks" id="toc-recurrent-neural-networks" class="nav-link" data-scroll-target="#recurrent-neural-networks"><span class="toc-section-number">2.0.3</span>  Recurrent neural networks</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Deep learning</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<p>Deep RL uses deep neural networks as function approximators, allowing complex representations of the value of state-action pairs to be learned. This section provides a very quick overview of deep learning. For additional details, refer to the excellent book of <span class="citation" data-cites="Goodfellow2016">Goodfellow et al. (<a href="references.html#ref-Goodfellow2016" role="doc-biblioref">2016</a>)</span>.</p>
<section id="deep-neural-networks" class="level3" data-number="2.0.1">
<h3 data-number="2.0.1" class="anchored" data-anchor-id="deep-neural-networks"><span class="header-section-number">2.0.1</span> Deep neural networks</h3>
<p>A deep neural network (DNN) consists of one input layer <span class="math inline">\(\mathbf{x}\)</span>, one or several hidden layers <span class="math inline">\(\mathbf{h_1}, \mathbf{h_2}, \ldots, \mathbf{h_n}\)</span> and one output layer <span class="math inline">\(\mathbf{y}\)</span> (<a href="#fig-dnn">Figure&nbsp;<span>2.1</span></a>).</p>
<div id="fig-dnn" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="img/dnn.png" class="img-fluid figure-img" style="width:60.0%"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;2.1: Architecture of a deep neural network. Figure taken from <span class="citation" data-cites="Nielsen2015">Nielsen (<a href="references.html#ref-Nielsen2015" role="doc-biblioref">2015</a>)</span>, CC-BY-NC.</figcaption><p></p>
</figure>
</div>
<p>Each layer <span class="math inline">\(k\)</span> (called <em>fully-connected</em>) transforms the activity of the previous layer (the vector <span class="math inline">\(\mathbf{h_{k-1}}\)</span>) into another vector <span class="math inline">\(\mathbf{h_{k}}\)</span> by multiplying it with a <strong>weight matrix</strong> <span class="math inline">\(W_k\)</span>, adding a <strong>bias</strong> vector <span class="math inline">\(\mathbf{b_k}\)</span> and applying a non-linear <strong>activation function</strong> <span class="math inline">\(f\)</span>.</p>
<p><span id="eq-fullyconnected"><span class="math display">\[
    \mathbf{h_{k}} = f(W_k \times \mathbf{h_{k-1}} + \mathbf{b_k})
\tag{2.1}\]</span></span></p>
<p>The activation function can theoretically be of any type as long as it is non-linear (sigmoid, tanh…), but modern neural networks use preferentially the <strong>Rectified Linear Unit</strong> (ReLU) function <span class="math inline">\(f(x) = \max(0, x)\)</span> or its parameterized variants.</p>
<p>The goal of learning is to find the weights and biases <span class="math inline">\(\theta\)</span> minimizing a given <strong>loss function</strong> on a training set <span class="math inline">\(\mathcal{D}\)</span>.</p>
<ul>
<li>In <em>regression</em> problems, the <strong>mean square error</strong> (mse) is minimized:</li>
</ul>
<p><span class="math display">\[
    \mathcal{L}(\theta) = \mathbb{E}_{\mathbf{x}, \mathbf{t} \in \mathcal{D}} [||\mathbf{t} - \mathbf{y}||^2]
\]</span></p>
<p>where <span class="math inline">\(\mathbf{x}\)</span> is the input, <span class="math inline">\(\mathbf{t}\)</span> the true output (defined in the training set) and <span class="math inline">\(\mathbf{y}\)</span> the prediction of the NN for the input <span class="math inline">\(\mathbf{x}\)</span>. The closer the prediction from the true value, the smaller the mse.</p>
<ul>
<li>In <em>classification</em> problems, the <strong>cross entropy</strong> (or negative log-likelihood) is minimized:</li>
</ul>
<p><span class="math display">\[
    \mathcal{L}(\theta) = - \mathbb{E}_{\mathbf{x}, \mathbf{t} \in \mathcal{D}} [\sum_i t_i \log y_i]
\]</span></p>
<p>where the log-likelihood of the prediction <span class="math inline">\(\mathbf{y}\)</span> to match the data <span class="math inline">\(\mathbf{t}\)</span> is maximized over the training set. The mse could be used for classification problems too, but the output layer usually has a softmax activation function for classification problems, which works nicely with the cross entropy loss function. See <a href="https://rdipietro.github.io/friendly-intro-to-cross-entropy-loss" class="uri">https://rdipietro.github.io/friendly-intro-to-cross-entropy-loss</a> for the link between cross entropy and log-likelihood and <a href="https://deepnotes.io/softmax-crossentropy" class="uri">https://deepnotes.io/softmax-crossentropy</a> for the interplay between softmax and cross entropy.</p>
<p>Once the loss function is defined, it has to be minimized by searching optimal values for the free parameters <span class="math inline">\(\theta\)</span>. This optimization procedure is based on <strong>gradient descent</strong>, which is an iterative procedure modifying estimates of the free parameters in the opposite direction of the gradient of the loss function:</p>
<p><span class="math display">\[
\Delta \theta = -\eta \, \nabla_\theta \mathcal{L}(\theta) = -\eta \, \frac{\partial \mathcal{L}(\theta)}{\partial \theta}
\]</span></p>
<p>The learning rate <span class="math inline">\(\eta\)</span> is chosen very small to ensure a smooth convergence. Intuitively, the gradient (or partial derivative) represents how the loss function changes when each parameter is slightly increased. If the gradient w.r.t a single parameter (e.g.&nbsp;a weight <span class="math inline">\(w\)</span>) is positive, increasing the weight increases the loss function (i.e.&nbsp;the error), so the weight should be slightly decreased instead. If the gradient is negative, one should increase the weight.</p>
<p>The question is now to compute the gradient of the loss function w.r.t all the parameters of the DNN, i.e.&nbsp;each single weight and bias. The solution is given by the <strong>backpropagation</strong> algorithm, which is simply an application of the <strong>chain rule</strong> to feedforward neural networks:</p>
<p><span class="math display">\[
    \frac{\partial \mathcal{L}(\theta)}{\partial W_k} = \frac{\partial \mathcal{L}(\theta)}{\partial \mathbf{y}} \times \frac{\partial \mathbf{y}}{\partial \mathbf{h_n}} \times \frac{\partial \mathbf{h_n}}{\partial \mathbf{h_{n-1}}} \times \ldots \times \frac{\partial \mathbf{h_k}}{\partial W_k}
\]</span></p>
<p>Each layer of the network adds a contribution to the gradient when going <strong>backwards</strong> from the loss function to the parameters. Importantly, all functions used in a NN are differentiable, i.e.&nbsp;those partial derivatives exist (and are easy to compute). For the fully connected layer represented by <a href="#eq-fullyconnected">Equation&nbsp;<span>2.1</span></a>, the partial derivative is given by:</p>
<p><span class="math display">\[
    \frac{\partial \mathbf{h_{k}}}{\partial \mathbf{h_{k-1}}} = f'(W_k \times \mathbf{h_{k-1}} + \mathbf{b_k}) \, W_k
\]</span></p>
<p>and its dependency on the parameters is:</p>
<p><span class="math display">\[
    \frac{\partial \mathbf{h_{k}}}{\partial W_k} = f'(W_k \times \mathbf{h_{k-1}} + \mathbf{b_k}) \, \mathbf{h_{k-1}}
\]</span> <span class="math display">\[
    \frac{\partial \mathbf{h_{k}}}{\partial \mathbf{b_k}} = f'(W_k \times \mathbf{h_{k-1}} + \mathbf{b_k})
\]</span></p>
<p>Activation functions are chosen to have an easy-to-compute derivative, such as the ReLU function:</p>
<p><span class="math display">\[
    f'(x) = \begin{cases} 1 \quad \text{if} \quad x &gt; 0 \\ 0 \quad \text{otherwise.} \end{cases}
\]</span></p>
<p>Partial derivatives are automatically computed by the underlying libraries, such as tensorflow, theano, pytorch, etc. The next step is choose an <strong>optimizer</strong>, i.e.&nbsp;a gradient-based optimization method allow to modify the free parameters using the gradients. Optimizers do not work on the whole training set, but use <strong>minibatches</strong> (a random sample of training examples: their number is called the <em>batch size</em>) to compute iteratively the loss function. The most popular optimizers are:</p>
<ul>
<li>SGD (stochastic gradient descent): vanilla gradient descent on random minibatches.</li>
<li>SGD with momentum (Nesterov or not): additional momentum to avoid local minima of the loss function.</li>
<li>Adagrad</li>
<li>Adadelta</li>
<li>RMSprop</li>
<li>Adam</li>
<li>Many others. Check the doc of keras to see what is available: <a href="https://keras.io/optimizers" class="uri">https://keras.io/optimizers</a></li>
</ul>
<p>See this useful post for a comparison of the different optimizers: <a href="http://ruder.io/optimizing-gradient-descent" class="uri">http://ruder.io/optimizing-gradient-descent</a> <span class="citation" data-cites="Ruder2016">(<a href="references.html#ref-Ruder2016" role="doc-biblioref">Ruder, 2016</a>)</span>. The common wisdom is that SGD with Nesterov momentum works best (i.e.&nbsp;it finds a better minimum) but its meta-parameters (learning rate, momentum) are hard to find, while Adam works out-of-the-box, at the cost of a slightly worse minimum. For deep RL, Adam is usually preferred, as the goal is to quickly find a working solution, not to optimize it to the last decimal.</p>
<!-- ![Comparison of different optimizers. Source: @Ruder2016, <http://ruder.io/optimizing-gradient-descent>.](img/optimizers.gif){#fig-optimizers width=50%} -->
<p>Additional regularization mechanisms are now typically part of DNNs in order to avoid overfitting (learning by heart the training set but failing to generalize): L1/L2 regularization, dropout, batch normalization, etc. Refer to <span class="citation" data-cites="Goodfellow2016">Goodfellow et al. (<a href="references.html#ref-Goodfellow2016" role="doc-biblioref">2016</a>)</span> for further details.</p>
</section>
<section id="convolutional-networks" class="level3" data-number="2.0.2">
<h3 data-number="2.0.2" class="anchored" data-anchor-id="convolutional-networks"><span class="header-section-number">2.0.2</span> Convolutional networks</h3>
<p>Convolutional Neural Networks (CNN) are an adaptation of DNNs to deal with highly dimensional input spaces such as images. The idea is that neurons in the hidden layer reuse (“share”) weights over the input image, as the features learned by early layers are probably local in visual classification tasks: in computer vision, an edge can be detected by the same filter all over the input image.</p>
<p>A <strong>convolutional layer</strong> learns to extract a given number of features (typically 16, 32, 64, etc) represented by 3x3 or 5x5 matrices. These matrices are then convoluted over the whole input image (or the previous convolutional layer) to produce <strong>feature maps</strong>. If the input image has a size NxMx1 (grayscale) or NxMx3 (colored), the convolutional layer will be a tensor of size NxMxF, where F is the number of extracted features. Padding issues may reduce marginally the spatial dimensions. One important aspect is that the convolutional layer is fully differentiable, so backpropagation and the usual optimizers can be used to learn the filters.</p>
<div id="fig-convlayer" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="img/convlayer.gif" class="img-fluid figure-img" style="width:50.0%"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;2.2: Convolutional layer. Source: <a href="https://github.com/vdumoulin/conv_arithmetic" class="uri">https://github.com/vdumoulin/conv_arithmetic</a>.</figcaption><p></p>
</figure>
</div>
<p>After a convolutional layer, the spatial dimensions are preserved. In classification tasks, it does not matter where the object is in the image, the only thing that matters is what it is: classification requires <strong>spatial invariance</strong> in the learned representations. The <strong>max-pooling layer</strong> was introduced to downsample each feature map individually and increase their spatial invariance. Each feature map is divided into 2x2 blocks (generally): only the maximal feature activation in that block is preserved in the max-pooling layer. This reduces the spatial dimensions by a factor two in each direction, but keeps the number of features equal.</p>
<div id="fig-maxpooling" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="img/maxpooling.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;2.3: Max-pooling layer. Source: Stanford’s CS231n course <a href="http://cs231n.github.io/convolutional-networks" class="uri">http://cs231n.github.io/convolutional-networks</a></figcaption><p></p>
</figure>
</div>
<p>A convolutional neural network is simply a sequence of convolutional layers and max-pooling layers (sometime two convolutional layers are applied in a row before max-pooling, as in VGG <span class="citation" data-cites="Simonyan2015">(<a href="references.html#ref-Simonyan2015" role="doc-biblioref">Simonyan and Zisserman, 2015</a>)</span>), followed by a couple of fully-connected layers and a softmax output layer. <a href="#fig-alexnet">Figure&nbsp;<span>2.4</span></a> shows the architecture of AlexNet, the winning architecture of the ImageNet challenge in 2012 <span class="citation" data-cites="Krizhevsky2012">(<a href="references.html#ref-Krizhevsky2012" role="doc-biblioref">Krizhevsky et al., 2012</a>)</span>.</p>
<div id="fig-alexnet" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="img/alexnet.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;2.4: Architecture of the AlexNet CNN. Taken from <span class="citation" data-cites="Krizhevsky2012">Krizhevsky et al. (<a href="references.html#ref-Krizhevsky2012" role="doc-biblioref">2012</a>)</span>.</figcaption><p></p>
</figure>
</div>
<p>Many improvements have been proposed since 2012 (e.g.&nbsp;ResNets <span class="citation" data-cites="He2015">(<a href="references.html#ref-He2015" role="doc-biblioref">He et al., 2015</a>)</span>) but the idea stays similar. Generally, convolutional and max-pooling layers are alternated until the spatial dimensions are so reduced (around 10x10) that they can be put into a single vector and fed into a fully-connected layer. This is <strong>NOT</strong> the case in deep RL! Contrary to object classification, spatial information is crucial in deep RL: position of the ball, position of the body, etc. It matters whether the ball is to the right or to the left of your paddle when you decide how to move it. Max-pooling layers are therefore omitted and the CNNs only consist of convolutional and fully-connected layers. This greatly increases the number of weights in the networks, hence the number of training examples needed to train the network. This is still the main limitation of using CNNs in deep RL.</p>
</section>
<section id="recurrent-neural-networks" class="level3" data-number="2.0.3">
<h3 data-number="2.0.3" class="anchored" data-anchor-id="recurrent-neural-networks"><span class="header-section-number">2.0.3</span> Recurrent neural networks</h3>
<p>Feedforward neural networks learn to efficiently map static inputs <span class="math inline">\(\mathbf{x}\)</span> to outputs <span class="math inline">\(\mathbf{y}\)</span> but have no memory or context: the output at time <span class="math inline">\(t\)</span> does not depend on the inputs at time <span class="math inline">\(t-1\)</span> or <span class="math inline">\(t-2\)</span>, only the one at time <span class="math inline">\(t\)</span>. This is problematic when dealing with video sequences for example: if the task is to classify videos into happy/sad, a frame by frame analysis is going to be inefficient (most frames a neutral). Concatenating all frames in a giant input vector would increase dramatically the complexity of the classifier and no generalization can be expected.</p>
<p>Recurrent Neural Networks (RNN) are designed to deal with time-varying inputs, where the relevant information to take a decision at time <span class="math inline">\(t\)</span> may have happened at different times in the past. The general structure of a RNN is depicted on <a href="#fig-rnn">Figure&nbsp;<span>2.5</span></a>:</p>
<div id="fig-rnn" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="img/RNN-unrolled.png" class="img-fluid figure-img" style="width:90.0%"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;2.5: Architecture of a RNN. Left: recurrent architecture. Right: unrolled network, showing that a RNN is equivalent to a deep network. Taken from <a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs" class="uri">http://colah.github.io/posts/2015-08-Understanding-LSTMs</a>.</figcaption><p></p>
</figure>
</div>
<p>The output <span class="math inline">\(\mathbf{h}_t\)</span> of the RNN at time <span class="math inline">\(t\)</span> depends on its current input <span class="math inline">\(\mathbf{x}_t\)</span>, but also on its previous output <span class="math inline">\(\mathbf{h}_{t-1}\)</span>, which, by recursion, depends on the whole history of inputs <span class="math inline">\((x_0, x_1, \ldots, x_t)\)</span>.</p>
<p><span class="math display">\[
    \mathbf{h}_t = f(W_x \, \mathbf{x}_{t} + W_h \, \mathbf{h}_{t-1} + \mathbf{b})
\]</span></p>
<p>Once unrolled, a RNN is equivalent to a deep network, with <span class="math inline">\(t\)</span> layers of weights between the first input <span class="math inline">\(\mathbf{x}_0\)</span> and the current output <span class="math inline">\(\mathbf{h}_t\)</span>. The only difference with a feedforward network is that weights are reused between two time steps / layers. <strong>Backpropagation though time</strong> (BPTT) can be used to propagate the gradient of the loss function backwards in time and learn the weights <span class="math inline">\(W_x\)</span> and <span class="math inline">\(W_h\)</span> using the usual optimizer (SGD, Adam…).</p>
<p>However, this kind of RNN can only learn short-term dependencies because of the <strong>vanishing gradient problem</strong> <span class="citation" data-cites="Hochreiter1991">(<a href="references.html#ref-Hochreiter1991" role="doc-biblioref">Hochreiter, 1991</a>)</span>. When the gradient of the loss function travels backwards from <span class="math inline">\(\mathbf{h}_t\)</span> to <span class="math inline">\(\mathbf{x}_0\)</span>, it will be multiplied <span class="math inline">\(t\)</span> times by the recurrent weights <span class="math inline">\(W_h\)</span>. If <span class="math inline">\(|W_h| &gt; 1\)</span>, the gradient will explode with increasing <span class="math inline">\(t\)</span>, while if <span class="math inline">\(|W_h| &lt; 1\)</span>, the gradient will vanish to 0.</p>
<p>The solution to this problem is provided by <strong>long short-term memory networks</strong> [LSTM;<span class="citation" data-cites="Hochreiter1997">Hochreiter and Schmidhuber (<a href="references.html#ref-Hochreiter1997" role="doc-biblioref">1997</a>)</span>]. LSTM layers maintain additionally a state <span class="math inline">\(\mathbf{C}_t\)</span> (also called context or memory) which is manipulated by three learnable gates (input, forget and output gates). As in regular RNNs, a <em>candidate state</em> <span class="math inline">\(\tilde{\mathbf{C}_t}\)</span> is computed based on the current input and the previous output:</p>
<p><span class="math display">\[
    \tilde{\mathbf{C}_t} = f(W_x \, \mathbf{x}_{t} + W_h \, \mathbf{h}_{t-1} + \mathbf{b})
\]</span></p>
<div id="fig-lstm" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="img/LSTM.png" class="img-fluid figure-img" style="width:40.0%"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;2.6: Architecture of a LSTM layer. Taken from <a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs" class="uri">http://colah.github.io/posts/2015-08-Understanding-LSTMs</a>.</figcaption><p></p>
</figure>
</div>
<p>The activation function <span class="math inline">\(f\)</span> is usually a tanh function. The input and forget learn to decide how the candidate state should be used to update the current state:</p>
<ul>
<li>The input gate decides which part of the candidate state <span class="math inline">\(\tilde{\mathbf{C}_t}\)</span> will be used to update the current state <span class="math inline">\(\mathbf{C}_t\)</span>:</li>
</ul>
<p><span class="math display">\[
    \mathbf{i}_t = \sigma(W^i_x \, \mathbf{x}_{t} + W^i_h \, \mathbf{h}_{t-1} + \mathbf{b}^i)
\]</span></p>
<p>The sigmoid activation function <span class="math inline">\(\sigma\)</span> is used to output a number between 0 and 1 for each neuron: 0 means the candidate state will not be used at all, 1 means completely.</p>
<ul>
<li>The forget gate decides which part of the current state should be kept or forgotten:</li>
</ul>
<p><span class="math display">\[
    \mathbf{f}_t = \sigma(W^f_x \, \mathbf{x}_{t} + W^f_h \, \mathbf{h}_{t-1} + \mathbf{b}^f)
\]</span></p>
<p>Similarly, 0 means that the corresponding element of the current state will be erased, 1 that it will be kept.</p>
<p>Once the input and forget gates are computed, the current state can be updated based on its previous value and the candidate state:</p>
<p><span class="math display">\[
   \mathbf{C}_t =  \mathbf{i}_t \odot \tilde{\mathbf{C}_t} + \mathbf{f}_t \odot \mathbf{C}_{t-1}
\]</span></p>
<p>where <span class="math inline">\(\odot\)</span> is the element-wise multiplication.</p>
<ul>
<li>The output gate finally learns to select which part of the current state <span class="math inline">\(\mathbf{C}_t\)</span> should be used to produce the current output <span class="math inline">\(\mathbf{h}_t\)</span>:</li>
</ul>
<p><span class="math display">\[
    \mathbf{o}_t = \sigma(W^o_x \, \mathbf{x}_{t} + W^o_h \, \mathbf{h}_{t-1} + \mathbf{b}^o)
\]</span></p>
<p><span class="math display">\[
    \mathbf{h}_t = \mathbf{o}_t \odot \tanh \mathbf{C}_t
\]</span></p>
<p>The architecture may seem complex, but everything is differentiable: backpropagation though time can be used to learn not only the input and recurrent weights for the candidate state, but also the weights and and biases of the gates. The main advantage of LSTMs is that they solve the vanishing gradient problem: if the input at time <span class="math inline">\(t=0\)</span> is important to produce a response at time <span class="math inline">\(t\)</span>, the input gate will learn to put it into the memory and the forget gate will learn to maintain in the current state until it is not needed anymore. During this “working memory” phase, the gradient is multiplied by exactly one as nothing changes: the dependency can be learned with arbitrary time delays!</p>
<p>There are alternatives to the classical LSTM layer such as the gated recurrent unit [GRU; <span class="citation" data-cites="Cho2014">Cho et al. (<a href="references.html#ref-Cho2014" role="doc-biblioref">2014</a>)</span>] or peephole connections <span class="citation" data-cites="Gers2001">(<a href="references.html#ref-Gers2001" role="doc-biblioref">Gers, 2001</a>)</span>. See <a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs" class="uri">http://colah.github.io/posts/2015-08-Understanding-LSTMs</a>, <a href="https://medium.com/mlreview/understanding-lstm-and-its-diagrams-37e2f46f1714" class="uri">https://medium.com/mlreview/understanding-lstm-and-its-diagrams-37e2f46f1714</a> or <a href="http://blog.echen.me/2017/05/30/exploring-lstms/" class="uri">http://blog.echen.me/2017/05/30/exploring-lstms/</a> for more visual explanations of LSTMs and their variants.</p>
<p>RNNs are particularly useful for deep RL when considering POMDPs, i.e.&nbsp;partially observable problems. If an observation does not contain enough information about the underlying state (e.g.&nbsp;a single image does not contain speed information), LSTM can integrate these observations over time and learn to implicitly represent speed in its context vector, allowing efficient policies to be learned.</p>


<div id="refs" class="references csl-bib-body hanging-indent" role="doc-bibliography" style="display: none">
<div id="ref-Cho2014" class="csl-entry" role="doc-biblioentry">
Cho, K., van Merrienboer, B., Gulcehre, C., Bahdanau, D., Bougares, F., Schwenk, H., et al. (2014). Learning <span>Phrase Representations</span> using <span>RNN Encoder-Decoder</span> for <span>Statistical Machine Translation</span>. Available at: <a href="http://arxiv.org/abs/1406.1078">http://arxiv.org/abs/1406.1078</a>.
</div>
<div id="ref-Gers2001" class="csl-entry" role="doc-biblioentry">
Gers, F. (2001). Long <span>Short-Term Memory</span> in <span>Recurrent Neural Networks</span>. Available at: <a href="http://www.felixgers.de/papers/phd.pdf">http://www.felixgers.de/papers/phd.pdf</a>.
</div>
<div id="ref-Goodfellow2016" class="csl-entry" role="doc-biblioentry">
Goodfellow, I., Bengio, Y., and Courville, A. (2016). <em>Deep <span>Learning</span></em>. <span>MIT Press</span> Available at: <a href="http://www.deeplearningbook.org">http://www.deeplearningbook.org</a>.
</div>
<div id="ref-He2015" class="csl-entry" role="doc-biblioentry">
He, K., Zhang, X., Ren, S., and Sun, J. (2015). Deep <span>Residual Learning</span> for <span>Image Recognition</span>. Available at: <a href="http://arxiv.org/abs/1512.03385">http://arxiv.org/abs/1512.03385</a>.
</div>
<div id="ref-Hochreiter1991" class="csl-entry" role="doc-biblioentry">
Hochreiter, S. (1991). Untersuchungen zu dynamischen neuronalen <span>Netzen</span>. Available at: <a href="http://people.idsia.ch/~juergen/SeppHochreiter1991ThesisAdvisorSchmidhuber.pdf">http://people.idsia.ch/~juergen/SeppHochreiter1991ThesisAdvisorSchmidhuber.pdf</a>.
</div>
<div id="ref-Hochreiter1997" class="csl-entry" role="doc-biblioentry">
Hochreiter, S., and Schmidhuber, J. (1997). Long short-term memory. <em>Neural computation</em> 9, 1735–80. Available at: <a href="https://www.ncbi.nlm.nih.gov/pubmed/9377276">https://www.ncbi.nlm.nih.gov/pubmed/9377276</a>.
</div>
<div id="ref-Krizhevsky2012" class="csl-entry" role="doc-biblioentry">
Krizhevsky, A., Sutskever, I., and Hinton, G. E. (2012). <span>ImageNet Classification</span> with <span>Deep Convolutional Neural Networks</span>. in <em>Advances in <span>Neural Information Processing Systems</span> (<span>NIPS</span>)</em> Available at: <a href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf">https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf</a>.
</div>
<div id="ref-Nielsen2015" class="csl-entry" role="doc-biblioentry">
Nielsen, M. A. (2015). <em>Neural <span>Networks</span> and <span>Deep Learning</span></em>. <span>Determination Press</span> Available at: <a href="http://neuralnetworksanddeeplearning.com/">http://neuralnetworksanddeeplearning.com/</a>.
</div>
<div id="ref-Ruder2016" class="csl-entry" role="doc-biblioentry">
Ruder, S. (2016). An overview of gradient descent optimization algorithms. Available at: <a href="http://arxiv.org/abs/1609.04747">http://arxiv.org/abs/1609.04747</a>.
</div>
<div id="ref-Simonyan2015" class="csl-entry" role="doc-biblioentry">
Simonyan, K., and Zisserman, A. (2015). Very <span>Deep Convolutional Networks</span> for <span>Large-Scale Image Recognition</span>. <em>International Conference on Learning Representations (ICRL)</em>, 1–14. doi:<a href="https://doi.org/10.1016/j.infsof.2008.09.005">10.1016/j.infsof.2008.09.005</a>.
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./1.1-BasicRL.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Basics</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./2-Valuebased.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Value-based methods</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>