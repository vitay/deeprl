<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Deep learning – Deep Reinforcement Learning</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../src/2.3-DQN.html" rel="next">
<link href="../src/2.1-FunctionApproximation.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script src="../site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="../site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="../site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>html{ scroll-behavior: smooth; }</style>

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css">

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <a class="flex-grow-1 no-decor" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
          <h1 class="quarto-secondary-nav-title"><span class="chapter-title">Deep learning</span></h1>
        </a>     
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Deep Reinforcement Learning</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/vitay/deeprl" title="" class="quarto-navigation-tool px-1" aria-label=""><i class="bi bi-github"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../src/0-Introduction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text"><strong>Basic RL</strong></span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../src/1.1-Bandits.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Sampling and Bandits</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../src/1.2-MDP.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Markov Decision Process</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../src/1.3-DP.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Dynamic programming</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../src/1.4-MC.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Monte-Carlo methods</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../src/1.5-TD.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Temporal Difference algorithm</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text"><strong>Value-based deep RL</strong></span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../src/2.1-FunctionApproximation.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Function approximation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../src/2.2-DeepNetworks.html" class="sidebar-item-text sidebar-link active"><span class="chapter-title">Deep learning</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../src/2.3-DQN.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">DQN</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text"><strong>Policy-gradient methods</strong></span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../src/3.1-PolicyGradient.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Policy Gradient methods</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../src/3.2-ActorCritic.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Asynchronous Advantage Actor-Critic (A3C)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../src/3.3-ImportanceSampling.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Off-policy Actor-Critic</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../src/3.4-DPG.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Deep Deterministic Policy Gradient (DDPG)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../src/3.5-NaturalGradient.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Policy Optimization (TRPO, PPO)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../src/3.6-EntropyRL.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Maximum Entropy RL (SAC)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../src/3.7-DistributionalRL.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Distributional learning</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../src/3.8-OtherPolicyGradient.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Miscellaneous model-free algorithms</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../src/references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#deep-neural-networks" id="toc-deep-neural-networks" class="nav-link active" data-scroll-target="#deep-neural-networks">Deep neural networks</a></li>
  <li><a href="#convolutional-networks" id="toc-convolutional-networks" class="nav-link" data-scroll-target="#convolutional-networks">Convolutional networks</a></li>
  <li><a href="#recurrent-neural-networks" id="toc-recurrent-neural-networks" class="nav-link" data-scroll-target="#recurrent-neural-networks">Recurrent neural networks</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block"><span class="chapter-title">Deep learning</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>Deep RL uses deep neural networks as function approximators, allowing complex representations of the value of state-action pairs to be learned. This section provides a very quick overview of deep learning. For additional details, refer to the excellent book of <span class="citation" data-cites="Goodfellow2016">Goodfellow et al. (<a href="references.html#ref-Goodfellow2016" role="doc-biblioref">2016</a>)</span>.</p>
<section id="deep-neural-networks" class="level3">
<h3 class="anchored" data-anchor-id="deep-neural-networks">Deep neural networks</h3>
<p>A deep neural network (DNN) consists of one input layer <span class="math inline">\mathbf{x}</span>, one or several hidden layers <span class="math inline">\mathbf{h_1}, \mathbf{h_2}, \ldots, \mathbf{h_n}</span> and one output layer <span class="math inline">\mathbf{y}</span> (<a href="#fig-dnn" class="quarto-xref">Figure&nbsp;<span>7.1</span></a>).</p>
<div id="fig-dnn" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-dnn-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="img/dnn.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="Figure&nbsp;7.1: Architecture of a deep neural network. Figure Source: @Nielsen2015, CC-BY-NC."><img src="img/dnn.png" class="img-fluid figure-img" style="width:60.0%"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-dnn-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7.1: Architecture of a deep neural network. Figure Source: <span class="citation" data-cites="Nielsen2015">Nielsen (<a href="references.html#ref-Nielsen2015" role="doc-biblioref">2015</a>)</span>, CC-BY-NC.
</figcaption>
</figure>
</div>
<p>Each layer <span class="math inline">k</span> (called <em>fully-connected</em>) transforms the activity of the previous layer (the vector <span class="math inline">\mathbf{h_{k-1}}</span>) into another vector <span class="math inline">\mathbf{h_{k}}</span> by multiplying it with a <strong>weight matrix</strong> <span class="math inline">W_k</span>, adding a <strong>bias</strong> vector <span class="math inline">\mathbf{b_k}</span> and applying a non-linear <strong>activation function</strong> <span class="math inline">f</span>.</p>
<p><span id="eq-fullyconnected"><span class="math display">
    \mathbf{h_{k}} = f(W_k \times \mathbf{h_{k-1}} + \mathbf{b_k})
\tag{7.1}</span></span></p>
<p>The activation function can theoretically be of any type as long as it is non-linear (sigmoid, tanh…), but modern neural networks use preferentially the <strong>Rectified Linear Unit</strong> (ReLU) function <span class="math inline">f(x) = \max(0, x)</span> or its parameterized variants.</p>
<p>The goal of learning is to find the weights and biases <span class="math inline">\theta</span> minimizing a given <strong>loss function</strong> on a training set <span class="math inline">\mathcal{D}</span>.</p>
<ul>
<li>In <em>regression</em> problems, the <strong>mean square error</strong> (mse) is minimized:</li>
</ul>
<p><span class="math display">
    \mathcal{L}(\theta) = \mathbb{E}_{\mathbf{x}, \mathbf{t} \in \mathcal{D}} [||\mathbf{t} - \mathbf{y}||^2]
</span></p>
<p>where <span class="math inline">\mathbf{x}</span> is the input, <span class="math inline">\mathbf{t}</span> the true output (defined in the training set) and <span class="math inline">\mathbf{y}</span> the prediction of the NN for the input <span class="math inline">\mathbf{x}</span>. The closer the prediction from the true value, the smaller the mse.</p>
<ul>
<li>In <em>classification</em> problems, the <strong>cross entropy</strong> (or negative log-likelihood) is minimized:</li>
</ul>
<p><span class="math display">
    \mathcal{L}(\theta) = - \mathbb{E}_{\mathbf{x}, \mathbf{t} \in \mathcal{D}} [\sum_i t_i \log y_i]
</span></p>
<p>where the log-likelihood of the prediction <span class="math inline">\mathbf{y}</span> to match the data <span class="math inline">\mathbf{t}</span> is maximized over the training set. The mse could be used for classification problems too, but the output layer usually has a softmax activation function for classification problems, which works nicely with the cross entropy loss function. See <a href="https://rdipietro.github.io/friendly-intro-to-cross-entropy-loss" class="uri">https://rdipietro.github.io/friendly-intro-to-cross-entropy-loss</a> for the link between cross entropy and log-likelihood and <a href="https://deepnotes.io/softmax-crossentropy" class="uri">https://deepnotes.io/softmax-crossentropy</a> for the interplay between softmax and cross entropy.</p>
<p>Once the loss function is defined, it has to be minimized by searching optimal values for the free parameters <span class="math inline">\theta</span>. This optimization procedure is based on <strong>gradient descent</strong>, which is an iterative procedure modifying estimates of the free parameters in the opposite direction of the gradient of the loss function:</p>
<p><span class="math display">
\Delta \theta = -\eta \, \nabla_\theta \mathcal{L}(\theta) = -\eta \, \frac{\partial \mathcal{L}(\theta)}{\partial \theta}
</span></p>
<p>The learning rate <span class="math inline">\eta</span> is chosen very small to ensure a smooth convergence. Intuitively, the gradient (or partial derivative) represents how the loss function changes when each parameter is slightly increased. If the gradient w.r.t a single parameter (e.g.&nbsp;a weight <span class="math inline">w</span>) is positive, increasing the weight increases the loss function (i.e.&nbsp;the error), so the weight should be slightly decreased instead. If the gradient is negative, one should increase the weight.</p>
<p>The question is now to compute the gradient of the loss function w.r.t all the parameters of the DNN, i.e.&nbsp;each single weight and bias. The solution is given by the <strong>backpropagation</strong> algorithm, which is simply an application of the <strong>chain rule</strong> to feedforward neural networks:</p>
<p><span class="math display">
    \frac{\partial \mathcal{L}(\theta)}{\partial W_k} = \frac{\partial \mathcal{L}(\theta)}{\partial \mathbf{y}} \times \frac{\partial \mathbf{y}}{\partial \mathbf{h_n}} \times \frac{\partial \mathbf{h_n}}{\partial \mathbf{h_{n-1}}} \times \ldots \times \frac{\partial \mathbf{h_k}}{\partial W_k}
</span></p>
<p>Each layer of the network adds a contribution to the gradient when going <strong>backwards</strong> from the loss function to the parameters. Importantly, all functions used in a NN are differentiable, i.e.&nbsp;those partial derivatives exist (and are easy to compute). For the fully connected layer represented by <a href="#eq-fullyconnected" class="quarto-xref">Equation&nbsp;<span>7.1</span></a>, the partial derivative is given by:</p>
<p><span class="math display">
    \frac{\partial \mathbf{h_{k}}}{\partial \mathbf{h_{k-1}}} = f'(W_k \times \mathbf{h_{k-1}} + \mathbf{b_k}) \, W_k
</span></p>
<p>and its dependency on the parameters is:</p>
<p><span class="math display">
    \frac{\partial \mathbf{h_{k}}}{\partial W_k} = f'(W_k \times \mathbf{h_{k-1}} + \mathbf{b_k}) \, \mathbf{h_{k-1}}
</span> <span class="math display">
    \frac{\partial \mathbf{h_{k}}}{\partial \mathbf{b_k}} = f'(W_k \times \mathbf{h_{k-1}} + \mathbf{b_k})
</span></p>
<p>Activation functions are chosen to have an easy-to-compute derivative, such as the ReLU function:</p>
<p><span class="math display">
    f'(x) = \begin{cases} 1 \quad \text{if} \quad x &gt; 0 \\ 0 \quad \text{otherwise.} \end{cases}
</span></p>
<p>Partial derivatives are automatically computed by the underlying libraries, such as tensorflow, theano, pytorch, etc. The next step is choose an <strong>optimizer</strong>, i.e.&nbsp;a gradient-based optimization method allow to modify the free parameters using the gradients. Optimizers do not work on the whole training set, but use <strong>minibatches</strong> (a random sample of training examples: their number is called the <em>batch size</em>) to compute iteratively the loss function. The most popular optimizers are:</p>
<ul>
<li>SGD (stochastic gradient descent): vanilla gradient descent on random minibatches.</li>
<li>SGD with momentum (Nesterov or not): additional momentum to avoid local minima of the loss function.</li>
<li>Adagrad</li>
<li>Adadelta</li>
<li>RMSprop</li>
<li>Adam</li>
<li>Many others. Check the doc of keras to see what is available: <a href="https://keras.io/optimizers" class="uri">https://keras.io/optimizers</a></li>
</ul>
<p>See this useful post for a comparison of the different optimizers: <a href="http://ruder.io/optimizing-gradient-descent" class="uri">http://ruder.io/optimizing-gradient-descent</a> <span class="citation" data-cites="Ruder2016">(<a href="references.html#ref-Ruder2016" role="doc-biblioref">Ruder, 2016</a>)</span>. The common wisdom is that SGD with Nesterov momentum works best (i.e.&nbsp;it finds a better minimum) but its meta-parameters (learning rate, momentum) are hard to find, while Adam works out-of-the-box, at the cost of a slightly worse minimum. For deep RL, Adam is usually preferred, as the goal is to quickly find a working solution, not to optimize it to the last decimal.</p>
<!-- ![Comparison of different optimizers. Source: @Ruder2016, <http://ruder.io/optimizing-gradient-descent>.](img/optimizers.gif){#fig-optimizers width=50%} -->
<p>Additional regularization mechanisms are now typically part of DNNs in order to avoid overfitting (learning by heart the training set but failing to generalize): L1/L2 regularization, dropout, batch normalization, etc. Refer to <span class="citation" data-cites="Goodfellow2016">Goodfellow et al. (<a href="references.html#ref-Goodfellow2016" role="doc-biblioref">2016</a>)</span> for further details.</p>
</section>
<section id="convolutional-networks" class="level3">
<h3 class="anchored" data-anchor-id="convolutional-networks">Convolutional networks</h3>
<p>Convolutional Neural Networks (CNN) are an adaptation of DNNs to deal with highly dimensional input spaces such as images. The idea is that neurons in the hidden layer reuse (“share”) weights over the input image, as the features learned by early layers are probably local in visual classification tasks: in computer vision, an edge can be detected by the same filter all over the input image.</p>
<p>A <strong>convolutional layer</strong> learns to extract a given number of features (typically 16, 32, 64, etc) represented by 3x3 or 5x5 matrices. These matrices are then convoluted over the whole input image (or the previous convolutional layer) to produce <strong>feature maps</strong>. If the input image has a size NxMx1 (grayscale) or NxMx3 (colored), the convolutional layer will be a tensor of size NxMxF, where F is the number of extracted features. Padding issues may reduce marginally the spatial dimensions. One important aspect is that the convolutional layer is fully differentiable, so backpropagation and the usual optimizers can be used to learn the filters.</p>
<div id="fig-convlayer" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-convlayer-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="img/convlayer.gif" class="lightbox" data-gallery="quarto-lightbox-gallery-2" title="Figure&nbsp;7.2: Convolutional layer. Source: https://github.com/vdumoulin/conv_arithmetic."><img src="img/convlayer.gif" class="img-fluid figure-img" style="width:50.0%"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-convlayer-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7.2: Convolutional layer. Source: <a href="https://github.com/vdumoulin/conv_arithmetic" class="uri">https://github.com/vdumoulin/conv_arithmetic</a>.
</figcaption>
</figure>
</div>
<p>After a convolutional layer, the spatial dimensions are preserved. In classification tasks, it does not matter where the object is in the image, the only thing that matters is what it is: classification requires <strong>spatial invariance</strong> in the learned representations. The <strong>max-pooling layer</strong> was introduced to downsample each feature map individually and increase their spatial invariance. Each feature map is divided into 2x2 blocks (generally): only the maximal feature activation in that block is preserved in the max-pooling layer. This reduces the spatial dimensions by a factor two in each direction, but keeps the number of features equal.</p>
<div id="fig-maxpooling" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-maxpooling-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="img/maxpooling.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3" title="Figure&nbsp;7.3: Max-pooling layer. Source: Stanford’s CS231n course http://cs231n.github.io/convolutional-networks"><img src="img/maxpooling.png" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-maxpooling-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7.3: Max-pooling layer. Source: Stanford’s CS231n course <a href="http://cs231n.github.io/convolutional-networks" class="uri">http://cs231n.github.io/convolutional-networks</a>
</figcaption>
</figure>
</div>
<p>A convolutional neural network is simply a sequence of convolutional layers and max-pooling layers (sometime two convolutional layers are applied in a row before max-pooling, as in VGG <span class="citation" data-cites="Simonyan2015">(<a href="references.html#ref-Simonyan2015" role="doc-biblioref">Simonyan and Zisserman, 2015</a>)</span>), followed by a couple of fully-connected layers and a softmax output layer. <a href="#fig-alexnet" class="quarto-xref">Figure&nbsp;<span>7.4</span></a> shows the architecture of AlexNet, the winning architecture of the ImageNet challenge in 2012 <span class="citation" data-cites="Krizhevsky2012">(<a href="references.html#ref-Krizhevsky2012" role="doc-biblioref">Krizhevsky et al., 2012</a>)</span>.</p>
<div id="fig-alexnet" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-alexnet-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="img/alexnet.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4" title="Figure&nbsp;7.4: Architecture of the AlexNet CNN. Source: @Krizhevsky2012."><img src="img/alexnet.png" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-alexnet-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7.4: Architecture of the AlexNet CNN. Source: <span class="citation" data-cites="Krizhevsky2012">Krizhevsky et al. (<a href="references.html#ref-Krizhevsky2012" role="doc-biblioref">2012</a>)</span>.
</figcaption>
</figure>
</div>
<p>Many improvements have been proposed since 2012 (e.g.&nbsp;ResNets <span class="citation" data-cites="He2015">(<a href="references.html#ref-He2015" role="doc-biblioref">He et al., 2015</a>)</span>) but the idea stays similar. Generally, convolutional and max-pooling layers are alternated until the spatial dimensions are so reduced (around 10x10) that they can be put into a single vector and fed into a fully-connected layer. This is <strong>NOT</strong> the case in deep RL! Contrary to object classification, spatial information is crucial in deep RL: position of the ball, position of the body, etc. It matters whether the ball is to the right or to the left of your paddle when you decide how to move it. Max-pooling layers are therefore omitted and the CNNs only consist of convolutional and fully-connected layers. This greatly increases the number of weights in the networks, hence the number of training examples needed to train the network. This is still the main limitation of using CNNs in deep RL.</p>
</section>
<section id="recurrent-neural-networks" class="level3">
<h3 class="anchored" data-anchor-id="recurrent-neural-networks">Recurrent neural networks</h3>
<p>Feedforward neural networks learn to efficiently map static inputs <span class="math inline">\mathbf{x}</span> to outputs <span class="math inline">\mathbf{y}</span> but have no memory or context: the output at time <span class="math inline">t</span> does not depend on the inputs at time <span class="math inline">t-1</span> or <span class="math inline">t-2</span>, only the one at time <span class="math inline">t</span>. This is problematic when dealing with video sequences for example: if the task is to classify videos into happy/sad, a frame by frame analysis is going to be inefficient (most frames a neutral). Concatenating all frames in a giant input vector would increase dramatically the complexity of the classifier and no generalization can be expected.</p>
<p>Recurrent Neural Networks (RNN) are designed to deal with time-varying inputs, where the relevant information to take a decision at time <span class="math inline">t</span> may have happened at different times in the past. The general structure of a RNN is depicted on <a href="#fig-rnn" class="quarto-xref">Figure&nbsp;<span>7.5</span></a>:</p>
<div id="fig-rnn" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-rnn-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="img/RNN-unrolled.png" class="lightbox" data-gallery="quarto-lightbox-gallery-5" title="Figure&nbsp;7.5: Architecture of a RNN. Left: recurrent architecture. Right: unrolled network, showing that a RNN is equivalent to a deep network. Source: http://colah.github.io/posts/2015-08-Understanding-LSTMs."><img src="img/RNN-unrolled.png" class="img-fluid figure-img" style="width:90.0%"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-rnn-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7.5: Architecture of a RNN. Left: recurrent architecture. Right: unrolled network, showing that a RNN is equivalent to a deep network. Source: <a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs" class="uri">http://colah.github.io/posts/2015-08-Understanding-LSTMs</a>.
</figcaption>
</figure>
</div>
<p>The output <span class="math inline">\mathbf{h}_t</span> of the RNN at time <span class="math inline">t</span> depends on its current input <span class="math inline">\mathbf{x}_t</span>, but also on its previous output <span class="math inline">\mathbf{h}_{t-1}</span>, which, by recursion, depends on the whole history of inputs <span class="math inline">(x_0, x_1, \ldots, x_t)</span>.</p>
<p><span class="math display">
    \mathbf{h}_t = f(W_x \, \mathbf{x}_{t} + W_h \, \mathbf{h}_{t-1} + \mathbf{b})
</span></p>
<p>Once unrolled, a RNN is equivalent to a deep network, with <span class="math inline">t</span> layers of weights between the first input <span class="math inline">\mathbf{x}_0</span> and the current output <span class="math inline">\mathbf{h}_t</span>. The only difference with a feedforward network is that weights are reused between two time steps / layers. <strong>Backpropagation though time</strong> (BPTT) can be used to propagate the gradient of the loss function backwards in time and learn the weights <span class="math inline">W_x</span> and <span class="math inline">W_h</span> using the usual optimizer (SGD, Adam…).</p>
<p>However, this kind of RNN can only learn short-term dependencies because of the <strong>vanishing gradient problem</strong> <span class="citation" data-cites="Hochreiter1991">(<a href="references.html#ref-Hochreiter1991" role="doc-biblioref">Hochreiter, 1991</a>)</span>. When the gradient of the loss function travels backwards from <span class="math inline">\mathbf{h}_t</span> to <span class="math inline">\mathbf{x}_0</span>, it will be multiplied <span class="math inline">t</span> times by the recurrent weights <span class="math inline">W_h</span>. If <span class="math inline">|W_h| &gt; 1</span>, the gradient will explode with increasing <span class="math inline">t</span>, while if <span class="math inline">|W_h| &lt; 1</span>, the gradient will vanish to 0.</p>
<p>The solution to this problem is provided by <strong>long short-term memory networks</strong> [LSTM;<span class="citation" data-cites="Hochreiter1997">Hochreiter and Schmidhuber (<a href="references.html#ref-Hochreiter1997" role="doc-biblioref">1997</a>)</span>]. LSTM layers maintain additionally a state <span class="math inline">\mathbf{C}_t</span> (also called context or memory) which is manipulated by three learnable gates (input, forget and output gates). As in regular RNNs, a <em>candidate state</em> <span class="math inline">\tilde{\mathbf{C}_t}</span> is computed based on the current input and the previous output:</p>
<p><span class="math display">
    \tilde{\mathbf{C}_t} = f(W_x \, \mathbf{x}_{t} + W_h \, \mathbf{h}_{t-1} + \mathbf{b})
</span></p>
<div id="fig-lstm" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-lstm-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="img/LSTM.png" class="lightbox" data-gallery="quarto-lightbox-gallery-6" title="Figure&nbsp;7.6: Architecture of a LSTM layer. Source: http://colah.github.io/posts/2015-08-Understanding-LSTMs."><img src="img/LSTM.png" class="img-fluid figure-img" style="width:40.0%"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-lstm-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7.6: Architecture of a LSTM layer. Source: <a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs" class="uri">http://colah.github.io/posts/2015-08-Understanding-LSTMs</a>.
</figcaption>
</figure>
</div>
<p>The activation function <span class="math inline">f</span> is usually a tanh function. The input and forget learn to decide how the candidate state should be used to update the current state:</p>
<ul>
<li>The input gate decides which part of the candidate state <span class="math inline">\tilde{\mathbf{C}_t}</span> will be used to update the current state <span class="math inline">\mathbf{C}_t</span>:</li>
</ul>
<p><span class="math display">
    \mathbf{i}_t = \sigma(W^i_x \, \mathbf{x}_{t} + W^i_h \, \mathbf{h}_{t-1} + \mathbf{b}^i)
</span></p>
<p>The sigmoid activation function <span class="math inline">\sigma</span> is used to output a number between 0 and 1 for each neuron: 0 means the candidate state will not be used at all, 1 means completely.</p>
<ul>
<li>The forget gate decides which part of the current state should be kept or forgotten:</li>
</ul>
<p><span class="math display">
    \mathbf{f}_t = \sigma(W^f_x \, \mathbf{x}_{t} + W^f_h \, \mathbf{h}_{t-1} + \mathbf{b}^f)
</span></p>
<p>Similarly, 0 means that the corresponding element of the current state will be erased, 1 that it will be kept.</p>
<p>Once the input and forget gates are computed, the current state can be updated based on its previous value and the candidate state:</p>
<p><span class="math display">
   \mathbf{C}_t =  \mathbf{i}_t \odot \tilde{\mathbf{C}_t} + \mathbf{f}_t \odot \mathbf{C}_{t-1}
</span></p>
<p>where <span class="math inline">\odot</span> is the element-wise multiplication.</p>
<ul>
<li>The output gate finally learns to select which part of the current state <span class="math inline">\mathbf{C}_t</span> should be used to produce the current output <span class="math inline">\mathbf{h}_t</span>:</li>
</ul>
<p><span class="math display">
    \mathbf{o}_t = \sigma(W^o_x \, \mathbf{x}_{t} + W^o_h \, \mathbf{h}_{t-1} + \mathbf{b}^o)
</span></p>
<p><span class="math display">
    \mathbf{h}_t = \mathbf{o}_t \odot \tanh \mathbf{C}_t
</span></p>
<p>The architecture may seem complex, but everything is differentiable: backpropagation though time can be used to learn not only the input and recurrent weights for the candidate state, but also the weights and and biases of the gates. The main advantage of LSTMs is that they solve the vanishing gradient problem: if the input at time <span class="math inline">t=0</span> is important to produce a response at time <span class="math inline">t</span>, the input gate will learn to put it into the memory and the forget gate will learn to maintain in the current state until it is not needed anymore. During this “working memory” phase, the gradient is multiplied by exactly one as nothing changes: the dependency can be learned with arbitrary time delays!</p>
<p>There are alternatives to the classical LSTM layer such as the gated recurrent unit [GRU; <span class="citation" data-cites="Cho2014">Cho et al. (<a href="references.html#ref-Cho2014" role="doc-biblioref">2014</a>)</span>] or peephole connections <span class="citation" data-cites="Gers2001">(<a href="references.html#ref-Gers2001" role="doc-biblioref">Gers, 2001</a>)</span>. See <a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs" class="uri">http://colah.github.io/posts/2015-08-Understanding-LSTMs</a>, <a href="https://medium.com/mlreview/understanding-lstm-and-its-diagrams-37e2f46f1714" class="uri">https://medium.com/mlreview/understanding-lstm-and-its-diagrams-37e2f46f1714</a> or <a href="http://blog.echen.me/2017/05/30/exploring-lstms/" class="uri">http://blog.echen.me/2017/05/30/exploring-lstms/</a> for more visual explanations of LSTMs and their variants.</p>
<p>RNNs are particularly useful for deep RL when considering POMDPs, i.e.&nbsp;partially observable problems. If an observation does not contain enough information about the underlying state (e.g.&nbsp;a single image does not contain speed information), LSTM can integrate these observations over time and learn to implicitly represent speed in its context vector, allowing efficient policies to be learned.</p>


<div id="refs" class="references csl-bib-body hanging-indent" role="list" style="display: none">
<div id="ref-Cho2014" class="csl-entry" role="listitem">
Cho, K., van Merrienboer, B., Gulcehre, C., Bahdanau, D., Bougares, F., Schwenk, H., et al. (2014). Learning <span>Phrase Representations</span> using <span>RNN Encoder-Decoder</span> for <span>Statistical Machine Translation</span>. Available at: <a href="http://arxiv.org/abs/1406.1078">http://arxiv.org/abs/1406.1078</a>.
</div>
<div id="ref-Gers2001" class="csl-entry" role="listitem">
Gers, F. (2001). Long <span>Short-Term Memory</span> in <span>Recurrent Neural Networks</span>. Available at: <a href="http://www.felixgers.de/papers/phd.pdf">http://www.felixgers.de/papers/phd.pdf</a>.
</div>
<div id="ref-Goodfellow2016" class="csl-entry" role="listitem">
Goodfellow, I., Bengio, Y., and Courville, A. (2016). <em>Deep <span>Learning</span></em>. MIT Press Available at: <a href="http://www.deeplearningbook.org">http://www.deeplearningbook.org</a>.
</div>
<div id="ref-He2015" class="csl-entry" role="listitem">
He, K., Zhang, X., Ren, S., and Sun, J. (2015). Deep <span>Residual Learning</span> for <span>Image Recognition</span>. Available at: <a href="http://arxiv.org/abs/1512.03385">http://arxiv.org/abs/1512.03385</a>.
</div>
<div id="ref-Hochreiter1991" class="csl-entry" role="listitem">
Hochreiter, S. (1991). Untersuchungen zu dynamischen neuronalen <span>Netzen</span>. Available at: <a href="http://people.idsia.ch/~juergen/SeppHochreiter1991ThesisAdvisorSchmidhuber.pdf">http://people.idsia.ch/~juergen/SeppHochreiter1991ThesisAdvisorSchmidhuber.pdf</a>.
</div>
<div id="ref-Hochreiter1997" class="csl-entry" role="listitem">
Hochreiter, S., and Schmidhuber, J. (1997). Long <span>Short-Term Memory</span>. <em>Neural Computation</em> 9, 1735–1780. doi:<a href="https://doi.org/10.1162/neco.1997.9.8.1735">10.1162/neco.1997.9.8.1735</a>.
</div>
<div id="ref-Krizhevsky2012" class="csl-entry" role="listitem">
Krizhevsky, A., Sutskever, I., and Hinton, G. E. (2012). <span>ImageNet Classification</span> with <span>Deep Convolutional Neural Networks</span>. in <em>Advances in <span>Neural Information Processing Systems</span> (<span>NIPS</span>)</em> Available at: <a href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf">https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf</a>.
</div>
<div id="ref-Nielsen2015" class="csl-entry" role="listitem">
Nielsen, M. A. (2015). <em>Neural <span>Networks</span> and <span>Deep Learning</span></em>. Determination Press Available at: <a href="http://neuralnetworksanddeeplearning.com/">http://neuralnetworksanddeeplearning.com/</a>.
</div>
<div id="ref-Ruder2016" class="csl-entry" role="listitem">
Ruder, S. (2016). An overview of gradient descent optimization algorithms. Available at: <a href="http://arxiv.org/abs/1609.04747">http://arxiv.org/abs/1609.04747</a>.
</div>
<div id="ref-Simonyan2015" class="csl-entry" role="listitem">
Simonyan, K., and Zisserman, A. (2015). Very <span>Deep Convolutional Networks</span> for <span>Large-Scale Image Recognition</span>. <em>International Conference on Learning Representations (ICRL)</em>, 1–14. doi:<a href="https://doi.org/10.1016/j.infsof.2008.09.005">10.1016/j.infsof.2008.09.005</a>.
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../src/2.1-FunctionApproximation.html" class="pagination-link" aria-label="Function approximation">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-title">Function approximation</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../src/2.3-DQN.html" class="pagination-link" aria-label="DQN">
        <span class="nav-page-text"><span class="chapter-title">DQN</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
<p><a href="http://creativecommons.org/licenses/by-nc-sa/4.0">Creative Commons BY-NC-SA 4.0</a>. Author <a href="mailto:julien.vitay@gmail.com">Julien Vitay</a></p>
</div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>
<script>var lightboxQuarto = GLightbox({"closeEffect":"zoom","descPosition":"bottom","loop":false,"openEffect":"zoom","selector":".lightbox"});
(function() {
  let previousOnload = window.onload;
  window.onload = () => {
    if (previousOnload) {
      previousOnload();
    }
    lightboxQuarto.on('slide_before_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      const href = trigger.getAttribute('href');
      if (href !== null) {
        const imgEl = window.document.querySelector(`a[href="${href}"] img`);
        if (imgEl !== null) {
          const srcAttr = imgEl.getAttribute("src");
          if (srcAttr && srcAttr.startsWith("data:")) {
            slideConfig.href = srcAttr;
          }
        }
      } 
    });
  
    lightboxQuarto.on('slide_after_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(slideNode);
      }
    });
  
  };
  
})();
          </script>




<script src="../site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>